# SparkRepo
Spark Assignment
Question-1 Assignment on User & transaction Csv Data

•	Imported spark session from pyspark.sql.
•	Defined Functions to start & stop the Session
•	Created logger and configured.
•	Defined a method to reading The csv files into Dataframes.
•	Defined Function to join two datafreames and return new dataframe
•	Defined a method to counting the unique location for each product sold.
•	Created a new method to Find out products bought by each user.
•	Called the functions in driver file.
•	Defined a Function to find Total spending done by each user on each product.
• Tested the all the functions using unittest.

Question-2 Assignment log files into RDD .

•	Imported loggers for logging the information.
•	Defined a method to start and stop the session.
•	Defined a method to read the log files using sparkContext read the files in to rdd's.
•	And stored in another rdd and verified testcases actual and expected.
•	Called the rdd file from the function created through driver.
•	Defined a method to count rdd lines count.
•	Defined a function to Fing the number of times the “WARN ” is repeated in rdd file.
•	Defined a function to Count number of api_clients in the file
•	Defined a function to Client did most HTTP requests in the file.
•	Defined a function to Most failed clients.
•	Defined a function to Most active repository.
•	Tested the all the functions using unittest.
